import re
import numpy as np

class ExplainabilityEngine:
    def __init__(self, classifier):
        self.clf = classifier

    def explain(self, text: str, initial_score: float, triggers: list, entities: dict) -> dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –≤–µ—Ä–¥–∏–∫—Ç–∞ –æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ 'Highlights' (—Å–ª–æ–≤–æ, —Ç–∏–ø, –æ—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è).
        """
        words = text.split()
        highlights = []
        
        # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–¥–µ–ª–µ–Ω–∏—è (–ü—Ä–∞–≤–∏–ª–∞ –∏ NER)
        # –ú—ã –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –∏—Ö, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ "–¢–≤–µ—Ä–¥—ã–µ" –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
        
        # –í—ã–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤
        for pattern_str in triggers:
            # –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —Å–ø–∞–Ω (–∏–Ω—Ç–µ—Ä–≤–∞–ª)
            try:
                for match in re.finditer(pattern_str, text, re.IGNORECASE):
                    highlights.append({
                        "span": match.span(),
                        "word": match.group(),
                        "type": "TRIGGER",
                        "impact": 1.0 # –ü–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ
                    })
            except:
                pass

        # –í—ã–¥–µ–ª–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π (NER)
        for ent_type, vals in entities.items():
            for val in vals:
                # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ
                # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å span –∏–∑ NER –º–æ–¥–µ–ª–∏
                start = text.lower().find(val.lower()) # –ë–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫
                if start != -1:
                    highlights.append({
                        "span": (start, start + len(val)),
                        "word": text[start:start+len(val)],
                        "type": f"NER_{ent_type}",
                        "impact": 0.8
                    })

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è (–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π LIME/Occlusion)
        # –ú–∞—Å–∫–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–¥–µ–Ω–∏–µ ML score
        
        # –î–µ–ª–∞–µ–º —ç—Ç–æ, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ ML Score –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫
        if initial_score > 0.4: 
            base_score = initial_score
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–æ–≤–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–∏–µ–º–ª–µ–º
            clean_words = [w.strip(".,!?:") for w in words]
            
            for i, word in enumerate(clean_words):
                if len(word) < 3: continue 
                
                # –°–æ–∑–¥–∞–µ–º –≤–æ–∑–º—É—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–¥–∞–ª—è–µ–º —Å–ª–æ–≤–æ)
                perturbed_text = text.replace(word, "", 1)
                
                # –ü—Ä–µ–¥–∏–∫—Ç (–±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º)
                res = self.clf.predict(perturbed_text, strict_mode=True)
                new_score = res['ml_score']
                
                drop = base_score - new_score
                
                # –ï—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∑–∏–ª–æ –æ—Ü–µ–Ω–∫—É (>0.1), –æ–Ω–æ –≤–∞–∂–Ω–æ
                if drop > 0.05:
                    highlights.append({
                        "span": None, # –°–ª–æ–∂–Ω–æ –æ—Ç—Å–ª–µ–¥–∏—Ç—å —Å–ø–∞–Ω –ø–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã
                        "word": word,
                        "type": "ML_FACTOR",
                        "impact": round(drop, 3)
                    })

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏—è
        unique_highlights = {}
        for h in highlights:
            key = h['word'].lower()
            if key not in unique_highlights or h['impact'] > unique_highlights[key]['impact']:
                unique_highlights[key] = h
                
        return list(unique_highlights.values())

    def visualize(self, text, highlights):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —É–¥–æ–±–Ω—ã–π –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏"""
        vis_text = text
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏—è –ø–æ –¥–ª–∏–Ω–µ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∑–∞–º–µ–Ω—ã –ø–æ–¥—Å—Ç—Ä–æ–∫
        sorted_h = sorted(highlights, key=lambda x: len(x['word']), reverse=True)
        
        for h in sorted_h:
            word = h['word']
            tag = h['type']
            # –¶–≤–µ—Ç–æ–≤—ã–µ –∫–æ–¥—ã –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
            # –ö–†–ê–°–ù–´–ô –¥–ª—è –¢—Ä–∏–≥–≥–µ—Ä–∞, –ñ–ï–õ–¢–´–ô –¥–ª—è ML, –ì–û–õ–£–ë–û–ô –¥–ª—è NER
            replacement = f"[{word}]"
            
            if "TRIGGER" in tag:
                replacement = f"üî¥[{word}]"
            elif "NER" in tag:
                replacement = f"üîµ[{word}]"
            elif "ML" in tag:
                 replacement = f"‚ö†Ô∏è[{word}]"
                 
            vis_text = vis_text.replace(word, replacement)
            
        return vis_text
